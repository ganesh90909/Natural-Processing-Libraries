{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analyzers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **textblob.sentiments** module contains two sentiment alalysis implementations namely ***PatternAnalyzer***(default which belongs to pattern library) and ***NaiveBayesAnalyzer*** (NLTK classifier trained on movie reviews corpus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(classification='pos', p_pos=0.7996209910191279, p_neg=0.2003790089808724)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#overriding the default pattern analysr\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "\n",
    "text=TextBlob('I love this library',analyzer=NaiveBayesAnalyzer())\n",
    "text.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.5, subjectivity=0.6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pattern analyzer\n",
    "from textblob.sentiments import PatternAnalyzer\n",
    "blob=TextBlob('I love this library',analyzer=PatternAnalyzer())\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *words* and *sentences* properties are helpers that use the ***textblob.tokenizers.WordTokenizer***\n",
    "and ***textblob.tokenizers.SentenceTokenizer*** classes, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from those, we can use other tokenizers like **TabTokenizer** and **BlanklineTokenizer** imported from NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TabTokenizer,BlanklineTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['This is', 'a rather tabby', 'blob.'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = TabTokenizer()\n",
    "blob = TextBlob(\"This is\\ta rather tabby\\tblob.\", tokenizer=tokenizer)\n",
    "blob.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['This is', 'a rather tabby', 'blob.'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BlanklineTokenizer()\n",
    "blob = TextBlob(\"This is\\n\\n a rather tabby\\n\\nblob.\", tokenizer=tokenizer)\n",
    "blob.tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noun Phrase chunkers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextBlob currently has two noun phrases chunker implementations, ***textblob.np_extractors.FastNPExtractor***(default, based on Shlomi Babluki’s implementation) and ***textblob.np_extractors.ConllExtractor***, which uses the CoNLL 2000 corpus to train a tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['python', 'high-level programming language'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ConllEtractor\n",
    "from textblob import TextBlob\n",
    "from textblob.np_extractors import ConllExtractor\n",
    "extractor = ConllExtractor()\n",
    "blob = TextBlob(\"Python is a high-level programming language.\", np_extractor=extractor)\n",
    "blob.noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['python'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FastNPExtractor\n",
    "from textblob.np_extractors import FastNPExtractor\n",
    "extractor = FastNPExtractor()\n",
    "blob = TextBlob(\"Python is a high-level programming language.\", np_extractor=extractor)\n",
    "blob.noun_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Taggers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextBlob currently has two POS tagger implementations, located in *textblob.taggers*. The default is the ***PatternTagger*** which uses the same implementation as the pattern library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second implementation is NLTKTagger which uses NLTK’s TreeBank tagger. Numpy is required to use the ***NLTKTagger***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the tokenizers and noun phrase chunkers, we can explicitly specify which POS tagger to use by passing a tagger instance to the constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Tag', 'NN'), ('You', 'PRP'), (\"'re\", 'VBP'), ('It', 'PRP')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.taggers import NLTKTagger\n",
    "nltk_tagger = NLTKTagger()\n",
    "blob = TextBlob(\"Tag! You're It!\", pos_tagger=nltk_tagger)\n",
    "blob.pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Tag', 'NN'), ('You', 'PRP'), (\"'\", 'POS'), ('re', 'NN'), ('It', 'PRP')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob.taggers import PatternTagger\n",
    "pattern_tagger = PatternTagger()\n",
    "blob = TextBlob(\"Tag! You're It!\", pos_tagger=pattern_tagger)\n",
    "blob.pos_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsers can also be passed to TextBlob constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Parsing/VBG/B-VP/O is/VBZ/I-VP/O fun/NN/B-NP/O ././O/O'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.parsers import PatternParser\n",
    "blob = TextBlob(\"Parsing is fun.\", parser=PatternParser())\n",
    "blob.parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class ***textblob.classifiers.BaseClassifier(train_set, feature_extractor=<function ba-\n",
    "sic_extractor>, format=None, **kwargs)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class ***textblob.classifiers.DecisionTreeClassifier(train_set, feature_extractor=<function ba- sic_extractor>, format=None,\n",
    "**kwargs)*** A classifier based on the decision tree algorithm, as implemented in NLTK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class ***textblob.classifiers.MaxEntClassifier(train_set, feature_extractor=<function ba-\n",
    "sic_extractor>, format=None, **kwargs)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class ***textblob.classifiers.NLTKClassifier(train_set, feature_extractor=<function ba-\n",
    "sic_extractor>, format=None, **kwargs)***\n",
    "\n",
    "<li>Example:</li>\n",
    "<li>class MyClassifier(NLTKClassifier):\n",
    "nltk_class = nltk.classify.svm.SvmClassifier</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class ***textblob.classifiers.NaiveBayesClassifier(train_set, feature_extractor=<function basic_extractor>, format=None,\n",
    "**kwargs)*** A classifier based on the Naive Bayes algorithm, as implemented in NLTK.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class ***textblob.classifiers.PositiveNaiveBayesClassifier(positive_set, unlabeled_set, feature_extractor=<function contains_extractor>, positive_prob_prior=0.5, **kwargs)***\n",
    "A variant of the Naive Bayes Classifier that performs binary classification with partially-labeled training sets, i.e. when only one class is labeled and the other is not. Assuming a prior distribution on the two labels, uses the unlabeled set to estimate the frequencies of the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blobber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class ***textblob.blob.Blobber(tokenizer=None, pos_tagger=None, np_extractor=None, ana- lyzer=None, parser=None, classifier=None)***\n",
    "A factory for TextBlobs that all share the same tagger, tokenizer, parser, classifier, and np_extractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Blobber\n",
    "from textblob.taggers import NLTKTagger\n",
    "from textblob.tokenizers import SentenceTokenizer\n",
    "tb = Blobber(pos_tagger=NLTKTagger(), tokenizer=SentenceTokenizer())\n",
    "blob1 = tb(\"This is one blob.\")\n",
    "blob2 = tb(\"This blob has the same tagger and tokenizer.\")\n",
    "blob1.pos_tagger is blob2.pos_tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
